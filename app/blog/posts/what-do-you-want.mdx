---
title: 'What Do You Want?'
publishedAt: '2025-07-06'
summary: 'My time working with Cursor'
---

This past week, I spent time working with Cursor in agent mode, porting an AI recipe app from Next.js to Expo in React Native. I had previously worked with Cursor in a vibecoding hackathon. In that experience working with other developers to make a rhythm game, it was pure slop. We would prompt and see if we liked it, then prompted the AI again to see if that worked. It was a dissatisfying experience—the game would start to take shape then fall apart and break. We couldn't get what we wanted. What I then later came to realize is we didn't know what we wanted, and neither did the AI agent.

The experience of not getting what I wanted from the AI again brought to mind working with a client who didn't know what they wanted. The client will have lots of opinions about the output, but no real idea of what they wanted, so they could only suggest changes that moved towards some idea they had in their head of what they wanted the product to be. It's a difficult position to be in when you're inexperienced or don't have the confidence to ask questions to get at what the client really wants from the product.

I found myself in the position of being that client who kept asking "Well, how about making that button red. No, not that kind of red. No, I want it to be RED." I was the client that didn't know what I wanted, so the AI agent would keep guessing at what I wanted. This wastes time, muddies up the codebase, and is a dissatisfying approach to writing code.

This time working with Cursor, I knew what I wanted. I took the time to work with the agent to write project specs. I had the agent ask me questions about features I wanted, how I wanted them implemented, and coding workflow. It was a much more successful workflow. I knew exactly what I wanted from the features and how the codebase worked. Documentation and maintaining project and engineering specs for my project was vital and led to my successes. Any failures I encountered were from not properly understanding what I wanted from a feature and how it should work.

My time working extensively with an AI agent was an exercise in project management. It felt like working with a really talented engineer with bad practices. I had to be vigilant and read through all code changes and maintain documentation. It was a great exercise to see what I could accomplish letting the agent do most of the work. It taught me a lot about the strengths and weaknesses of AI coding. It also taught me the value of knowing what you want—truly, deeply, knowing what it is you actually want and not what you think you want.